총 5가지의 단계로 나눠진다.

1. 데이터 로드 및 전처리
2. 모델 설계 
3. 모델 컴파일 및 학습
4. 학습 결과 평가 및 시각화
5. 결과 저장 및 모델 저장



1. 데이터 로드 및 전처리

import os
import numpy as np
import cv2
import random
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

/////////////////////////////////////////////////////////////

os: 운영 체제(OS)와 상호작용할 수 있게 한다.

numpy: np라는 이름으로 불리며, 고성능의 수학 연산을 지원하는 라이브러리이다.

cv2: OpenCV라는 컴퓨터 비전 라이브러리이며 이미지와 동영상을 처리하며, 이미지를 읽고 크기를 조정할 수 있다.

matplotlib.pyplot: plt로 불리며, 그래프 같은것들을 보여주는 역할이다.

train_test_split: Scikit-learn 라이브러리에서 제공하는 함수로 데이터를 학습용과 테스트용으로 나누는데 사용된다.

/////////////////////////////////////////////////////////////

DATASET_PATH = '/content/'

/////////////////////////////////////////////////////////////

DATASET_PATH: 데이터셋이 저장된 경로, 코랩의 특정 폴더에 해양 쓰레기 데이터를 저장한 후, 그 경로를 지정한 것이다.

/////////////////////////////////////////////////////////////

def load_images_from_folder(folder):
    images = []
    labels = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder, filename))
        if img is not None:
            # 이미지 크기를 고정 크기로 조정
            img = cv2.resize(img, (128, 128))
            # 임의의 label을 추가하는 코드 (실제 환경에서는 object bounding box 필요)
            label = [random.randint(0, 127), random.randint(0, 127), random.randint(64, 128), random.randint(64, 128)]  # 임의의 바운딩 박스
            images.append(img)
            labels.append(label)
    return np.array(images), np.array(labels)

/////////////////////////////////////////////////////////////

# 데이터 셋에서 이미지 파일을 불러오는 함수이다.

* load_images_from_folder: 주어진 폴더에서 이미지를 불러오고, 그에 대한 바운딩 박스를 임의로 생성해 반환하는 함수이다.

os.listdir(folder): 해당 폴더 안에 있는 파일들의 리스트를 반환한다. Ex) folder 안에 있는 이미지 파일 이름들을 모두 가져온다.

cv2.imread(): OpenCV를 사용해 이미지 파일을 읽어온다. 이미지가 없으면 None을 반환한다.

random.randint(): 임의의 정수를 생성, 위 코드에서는 임의의 바운딩 박스 좌표를 설정하는 것이다.

np.array(): NumPy 배열로 변환해 반환한다.이는 학습 과정에서 빠르게 연산하기 위해 필요하다.

/////////////////////////////////////////////////////////////

images, labels = load_images_from_folder(DATASET_PATH)
x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=1234)

/////////////////////////////////////////////////////////////

# 첫 번째 코드는 이미지와 라벨 데이터를 로드하는 코드
# 두 번째 코드는 Tran-test 분할 코드, 쉽게 설명하자면 학습용 데이터와 테스트용 데이터를 분리하는 것이다.

* test_size=0.2 : 데이터의 0.2 배, 즉 20%를 테스트용으로 사용한다는 뜻이다

* random_state=1234 : 무작위성을 고정하기 위한 값으로, 매번 다른 결과가 나오면 안되므로 마인크래프트의 시드 비슷한 역할을 한다. 현재 1234 시드라는 뜻

/////////////////////////////////////////////////////////////

print(f'훈련 데이터: (800, 128, 128, 3), 라벨: (800, 4)')
print(f'테스트 데이터: (200, 128, 128, 3), 라벨: (200, 4)')

/////////////////////////////////////////////////////////////

* 훈련 데이터 ( 800, 128, 128, 3) : "800"개의 "128"x"128" 크기의 이미지, "3"은 RGB 채널을 뜻함

* 라벨 (800, 4) : 각 이미지에 대해 바운딩 박스 좌표 4개(x1,y1,x2,y2)를 예측하는 라벨이 있음을 뜻한다.

* 테스트 데이터: (200, 128, 128, 3) : 테스트용 데이터가 "200"개의 이미지로 분리, 분할 되었음을 뜻한다. 이미지의 크기나 RGB 채널은 동일함

* 라벨 (200, 4) : 이미지 갯수만 다를뿐 박스 좌표 4개는 동일함.

/// 좌표가 4개인 이유 : 사각형을 바운딩 박스를 그려야 하기 떄문에 꼭짓점 4개를 뜻함.

/////////////////////////////////////////////////////////////

# 데이터 로드 및 전처리

import os
import numpy as np
import cv2
import random
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

DATASET_PATH = '/content/'

def load_images_from_folder(folder):
    images = []
    labels = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder, filename))
        if img is not None:
            img = cv2.resize(img, (128, 128))
            label = [random.randint(0, 127), random.randint(0, 127), random.randint(64, 128), random.randint(64, 128)] 
            images.append(img)
            labels.append(label)
    return np.array(images), np.array(labels)

images, labels = load_images_from_folder(DATASET_PATH)

x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

print(f'훈련 데이터: (800, 128, 128, 3), 라벨: (800, 4)')
print(f'테스트 데이터: (200, 128, 128, 3), 라벨: (200, 4)')

////////////////////////////////////////////////////////////////////

2. 모델 설계 

import tensorflow as tf
from tensorflow.keras import layers, models

////////////////////////////////////////////////////////////////////

import tensorflow as tf : tensorflow 라이브러리를 불러온다.
from tensorflow.keras import layers, models : layer - 신격망의 각 레이어를 정의할때 사용 / models - 딥러닝 모델 설계 및 컴파일에 사용

////////////////////////////////////////////////////////////////////

# CNN 모델 설계
def create_object_detection_model(input_shape):
    model = models.Sequential()

////////////////////////////////////////////////////////////////////

ef create_object_detection_model(input_shape) : 모델을 생성하는 함수를 정의한다. 여기서 (input_shape)는 이미지 형태를 나타난다.
아까의 훈련 데이터에서 (128, 128, 3)처럼 여기도 (128, 128, 3)을 입력하면 128x128 크기의 RGB 이미지라는 것이다.

model = models.Sequential() : Keras의 Sequential API를 사용하여 순차적인 모델을 생성한다. Sequential 모델은 레이어를 선형적으로 쌓는 방식

////////////////////////////////////////////////////////////////////

 # CNN 레이어 추가
    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))

////////////////////////////////////////////////////////////////////

model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape)) : 
* Conv2D 레이어: 2D convolutional 레이어를 추가한다.
* 32: 이 레이어에서 사용할 필터의 개수, 즉 32개의 특징 맵을 생성한다.
* (3,3) : 필터의 크기를 말한다.( 필터의 크기가 3x3이라는 뜻 )
* activation='relu': 활성화 함수로 ReLU(Rectified Linear Unit)를 사용한다.이는 비선형성을 추가하여 모델이 더 복잡한 패턴을 학습할 수 있도록 도와준다.
* input_shape=input_shape: 첫 번째 레이어에서 입력 형태를 지정한다. 이후 레이어에서는 자동으로 입력 형태를 추론함

////////////////////////////////////////////////////////////////////

model.add(layers.MaxPooling2D((2, 2)))

////////////////////////////////////////////////////////////////////

model.add(layers.MaxPooling2D((2, 2)))
* MaxPooling2D 레이어: 풀링 레이어를 추가하여 공간적 차원을 줄인다.
* (2, 2) : 2x2크기의 필터를 사용하여 2픽셀 단위로 이미지의 크기를 줄임 -> 계산량이 줄어들고 특징의 추상화로 과적힙 방지

////////////////////////////////////////////////////////////////////

  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))

////////////////////////////////////////////////////////////////////

  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
* 두 번째 Conv2D와 MaxPooling2D 추가 : 다음으로 64개의 필터를 사용하는 Conv@D 레이어를 추가하고, 다시 MaxPooling2D 레이어를
추가하여 특징맵의 차원을 줄인다. 이 단계에서 특징의 복잡성이 증가한다.

////////////////////////////////////////////////////////////////////

    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))

////////////////////////////////////////////////////////////////////

    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
* 세 번째 Conv2D와 MaxPooling2D 추가: 128개의 필터를 사용하는 Conv2D 레이어를 추가하고, 또 다시 MaxPooling2D 레이어를 추가한다.
모델이 깊어짐으로써 더 많은 특징을 추출할 수 있다.

////////////////////////////////////////////////////////////////////

 # Flatten하고 Fully Connected Layer로 연결
    model.add(layers.Flatten())

////////////////////////////////////////////////////////////////////

Flatten 레이어: 다차원 배열을 1차원으로 변환한다. 이 단계는 CNN에서 특징 추출을 마치고, fully connected layer에 입력하기 위해 데이터를 평평하게 만들기 위해 필요하다.

////////////////////////////////////////////////////////////////////

 model.add(layers.Dense(128, activation='relu'))

////////////////////////////////////////////////////////////////////

model.add(layers.Dense(128, activation='relu'))
Dense 레이어: 완전 연결층을 추가한다. 이 레이어는 128개의 뉴런으로 구성되며, ReLU 활성화 함수를 사용합니다. 이전 레이어에서 추출된 특징을 기반으로 더 복잡한 패턴을 학습한다.

////////////////////////////////////////////////////////////////////

   # 바운딩 박스 좌표 예측 (4개의 출력: x1, y1, x2, y2)
    model.add(layers.Dense(4, activation='sigmoid'))

////////////////////////////////////////////////////////////////////

model.add(layers.Dense(4, activation='sigmoid'))
* 마지막 레이어로 Dense 레이어를 추가하여 4개의 출력을 생성한다. 이 4개의 출력은 바운딩 박스 좌표로, 각각 x1, y1, x2, y2를 나타낸다.
* activation='sigmoid': 시그모이드 활성화 함수를 사용하여 0과 1 사이의 값을 출력한다. 이는 바운딩 박스의 좌표를 정규화하는 데 유용하다.

////////////////////////////////////////////////////////////////////

# CNN 모델 설계
def create_object_detection_model(input_shape):
    model = models.Sequential()

    # CNN 레이어 추가
    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(128, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))

    # Flatten하고 Fully Connected Layer로 연결
    model.add(layers.Flatten())
    model.add(layers.Dense(128, activation='relu'))

    # 바운딩 박스 좌표 예측 (4개의 출력: x1, y1, x2, y2)
    model.add(layers.Dense(4, activation='sigmoid'))

    return model  

////////////////////////////////////////////////////////////////////

3. 모델 컴파일 및 학습

////////////////////////////////////////////////////////////////////

# 모델 컴파일
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])

////////////////////////////////////////////////////////////////////

optimizer='adam': Adam 옵티마이저를 사용한다. ( Adam 옵티마이저는 딥러닝 문제에서 효과적으로 널리 사용되며, 학습률을 동적으로 저장하면서 모델의 가중치를 업데이트 한다. )
loss='mean_squared_error': 손실 함수로 평균 제곱 오차(MSE = Mean Squared Error)를 사용한다.

MSE : 예측 값과 실제 값의 차이를 제곱하여 평균을 낸 값이다. 주로 회귀 문제에서 사용되며, 출력이 연속적일때 사용한다.
+ 모델의 바운딩 좌표를 예측하기 떄문에 MSE를 사용한다.

metrics=['accuracy']: 모델의 성능을 평가할 지표로 정확도를 설정합니다.( 정확도 = accuracy )

정확도 : 올바르게 예측한 샘플의 비율이다.

////////////////////////////////////////////////////////////////////

# 모델 학습
history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), batch_size=32)

////////////////////////////////////////////////////////////////////

x_train: 훈련에 사용할 입력 데이터이다. 128x128 크기의 이미지가 포함된 배열

y_train: 마찬가지로 훈련에 사용할 출력 데이터, 각 이미지에 대한 바운딩 박스 좌표를 포함하는 배열

epochs=10:전체 훈련 데이터를 모델에 N번 반복할 것인지 지정 / 여기서는 10번 훈련한다는 것을 의미
+ 훈련 수가 많을수록 모델은 더 많은 학습을 하게 되지만 과적합의 위험도 커진다.

validation_data=(x_test, y_test): 모델의 성능을 평가할 검증 데이터이다. 훈련 중에 x_test와 y_test를 사용하여 모델이 얼마나 잘 일반화되고 있는지를 평가한다.

batch_size=32: 모델 훈련 시 한 번에 처리할 샘플의 수 / 여기서는 32개의 샘플을 한 번에 모델에 입력하여 가중치를 업데이트한다.
+ 배치 크기가 크면 훈련 시간이 증가 및 메모리 사용량 증가 , 작으면 빠르지만 학습이 불안정해짐


////////////////////////////////////////////////////////////////////

4. 학습 결과 평가 및 시각화

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////
